{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsgotti/TCC_Python/blob/main/Simplificado_Oversample_online_intervalo_de_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVbpsQNoXTMx",
        "outputId": "b2bb66c1-374f-4b7b-98bc-ede4b443e3e4"
      },
      "source": [
        "#carrega imports e instala o scikit-multiflow\n",
        "!pip install -U scikit-multiflow\n",
        "# Imports\n",
        "from skmultiflow.data import FileStream\n",
        "from skmultiflow.data import SEAGenerator\n",
        "from skmultiflow.evaluation import EvaluatePrequential\n",
        "from skmultiflow.bayes import NaiveBayes\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "from skmultiflow.trees import HoeffdingAdaptiveTreeClassifier\n",
        "from skmultiflow.trees import ExtremelyFastDecisionTreeClassifier\n",
        "from skmultiflow.meta import LearnPPNSEClassifier\n",
        "from skmultiflow.drift_detection import ADWIN\n",
        "from skmultiflow.meta import OzaBaggingClassifier\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "#carrega imports\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "from sklearn import datasets, linear_model\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from skmultiflow.lazy import KNNClassifier\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np\n",
        "from skmultiflow.data.file_stream import FileStream\n",
        "from skmultiflow.data.data_stream import DataStream\n",
        "from skmultiflow.trees import HoeffdingTreeClassifier\n",
        "from skmultiflow.evaluation import EvaluatePrequential\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "from skmultiflow.trees import HoeffdingTree\n",
        "from skmultiflow.meta import AdaptiveRandomForestClassifier\n",
        "from datetime import datetime, date"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multiflow\n",
            "  Downloading scikit_multiflow-0.5.3-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.7.3)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (2.4.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from scikit-multiflow) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.1.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "qJYI_23c8BdY",
        "outputId": "75566f89-6ce4-475c-adf9-cc133f002a7c"
      },
      "source": [
        "#segunda parte\n",
        "#importa arquivo para teste\n",
        "uploaded = files.upload()\n",
        "#Importa o arquivo para o colab\n",
        "import io\n",
        "\n",
        "#abre o arquivo no dataframe\n",
        "df = pd.read_csv(io.BytesIO(uploaded['tomcat2.csv']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16fe5470-5522-457f-b88a-c6eacf8241f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-16fe5470-5522-457f-b88a-c6eacf8241f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tomcat2.csv to tomcat2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pytFTI1C3Dlv"
      },
      "source": [
        "np.set_printoptions(formatter={'float_kind':'{:25f}'.format})\n",
        "\n",
        "#Etapa de upsampling\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "#Divide o dataframe em codigos 0 e 1, apenas o 1 sera usado\n",
        "\n",
        "m=df.code==0\n",
        "df_code0=df[m]\n",
        "df_code1=df[~m]\n",
        "\n",
        "print(df_code1.contains_bug.value_counts())\n",
        "\n",
        "# Separa classes minoritarias e majoritarias\n",
        "df_majority = df_code1[df_code1.contains_bug==0]\n",
        "df_minority = df_code1[df_code1.contains_bug==1]\n",
        "\n",
        "\n",
        "# Upsample de classe minoritaria\n",
        "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=123)\n",
        "\n",
        "\n",
        "# Combina classe majoritaria e minoritaria\n",
        "df_upsampled_partial = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "print(df_upsampled_partial.contains_bug.value_counts())\n",
        "df_upsampled = pd.concat([df_upsampled_partial, df_code0])\n",
        "print(df_upsampled.contains_bug.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGOtPCD73Igk"
      },
      "source": [
        "#Embaralha dataframe\n",
        "df_upsampled = df_upsampled.sample(frac=1)\n",
        "#Abre stream com dataframe upsampled\n",
        "stream = DataStream(df_upsampled)\n",
        "\n",
        "#Embaralha dataframe\n",
        "df_upsampled = df_upsampled.sample(frac=1)\n",
        "\n",
        "#Abre stream com dataframe upsampled\n",
        "stream = DataStream(df_upsampled)\n",
        "\n",
        "#Inicializa variaveis e lista que serão usadas, deve ser rodado a cada teste\n",
        "\n",
        "indexStream=1\n",
        "\n",
        "periodicidadeTreinamento = 100\n",
        "\n",
        "w = 100\n",
        "\n",
        "PREDICT = 0\n",
        "\n",
        "TRAIN = 1\n",
        "\n",
        "#Escolher o classificador\n",
        "\n",
        "#meta.AdaptiveRandomForestClassifier tmanho 100 nestimators 100\n",
        "#lazy.KNNClassifier k = 5\n",
        "#classifier = HoeffdingTree()\n",
        "classifier = OzaBaggingClassifier(base_estimator=HoeffdingTree(), n_estimators=20)\n",
        "#classifier = LearnPPNSEClassifier()\n",
        "#classifier = HoeffdingAdaptiveTreeClassifier()\n",
        "#classifier = ExtremelyFastDecisionTreeClassifier()\n",
        "#classifier = AdaptiveRandomForestClassifier(n_estimators=100)\n",
        "#classifier = KNNClassifier()\n",
        "\n",
        "correctness_dist = []\n",
        "i = 0\n",
        "\n",
        "poolCleanInstances = []\n",
        "poolDefectInducingInstances = []\n",
        "poolTrainInstances = []\n",
        "poolTrainClasses = []\n",
        "poolTrainInstances2= []\n",
        "\n",
        "##Cria a classe de recall\n",
        "class Recall:\n",
        "  recall0 = 0\n",
        "  recall1 = 0\n",
        "\n",
        "  b0 = 0\n",
        "  b1 = 0\n",
        "\n",
        "  alpha = 0.999\n",
        "\n",
        "  def updateRec0(self, value):\n",
        "    self.recall0 = value + self.alpha * self.recall0\n",
        "    self.b0 =  self.alpha * self.b0 + 1.0;\n",
        "\n",
        "  def getRecall0(self):\n",
        "    if self.b0 > 0:\n",
        "      #print(\"b0>0\")\n",
        "      #print(self.b0)\n",
        "      return self.recall0/self.b0\n",
        "    else:\n",
        "      #print(\"b0 not 0\")\n",
        "      #print(self.b0)\n",
        "      return 0\n",
        "\n",
        "  def updateRec1(self, value):\n",
        "    self.recall1 = value +  self.alpha * self.recall1\n",
        "    self.b1 =  self.alpha * self.b1 + 1.0;\n",
        "\n",
        "  def getRecall1(self):\n",
        "    if self.b1 > 0:\n",
        "      #print(\"b1>0\")\n",
        "      #print(self.b1)\n",
        "      return self.recall1/self.b1\n",
        "    else:\n",
        "      #print(\"b1 not 0\")\n",
        "      #print(self.b1)\n",
        "      return 0\n",
        "\n",
        "\n",
        "#Cria as listas de recall\n",
        "import math\n",
        "\n",
        "recall = Recall()\n",
        "\n",
        "recall0list = [0]\n",
        "recall1list = [0]\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "isFirstInstance = True\n",
        "#Roda enquanto ainda tem instancias na stream\n",
        "while (stream.has_more_samples()):\n",
        "  #Inicializa o classificador caso seja a primeira instancia\n",
        "  if(isFirstInstance and len(poolTrainInstances) > 0):\n",
        "    inst = poolTrainInstances[0]\n",
        "\n",
        "    inst2 = np.array([inst[0,1:14],inst[0,1:14]])\n",
        "    classe2 = np.array([0,1])\n",
        "\n",
        "    classifier.partial_fit(inst2, classe2,classes=stream.target_values)\n",
        "    isFirstInstance = False\n",
        "  #Incrementa o indexStream para comparar com o w e treinar classificador\n",
        "  indexStream = indexStream +1\n",
        "  #X são as caracteristicas da instancia e control é o code (0 ou 1)\n",
        "  X, control = stream.next_sample()\n",
        "  current_timestamp = X[0,0]\n",
        "  original_timestamp = X[0,16]\n",
        "  current_date = datetime.fromtimestamp(current_timestamp)\n",
        "  original_date = datetime.fromtimestamp(original_timestamp)\n",
        "  classe = int(X[0,15])\n",
        "  X2 = [X[0 ,1:14]]\n",
        "\n",
        "  #Se control for predict\n",
        "  if(control == PREDICT):\n",
        "    #usa o metodo predict e guarda em prediction\n",
        "    prediction = classifier.predict(X2)\n",
        "    #caso prediction acerte, faz update nas listas e no recall\n",
        "    if classe == prediction[0]:\n",
        "      correctness_dist.append(1)\n",
        "      #Entra se a classe eh 0 e da update no recall 0\n",
        "      if (classe == 0):\n",
        "        if not recall1list:\n",
        "          recall1list.append(0)\n",
        "        if recall1list:\n",
        "          recall1list.append(recall1list[-1])\n",
        "        TN = TN + 1\n",
        "        #print(\"TN ACERTOU\")\n",
        "        recall.updateRec0(1)\n",
        "        recall0list.append(recall.getRecall0())\n",
        "        #caso prediction erre, faz update nas listas e no recall\n",
        "      #Entra se a classe eh 1 e da update no recall 1\n",
        "      else:\n",
        "        if not recall1list:\n",
        "          recall1list.append(0)\n",
        "        if recall1list:\n",
        "          recall1list.append(recall1list[-1])\n",
        "        TP = TP + 1\n",
        "        recall.updateRec1(1)\n",
        "        recall1list.append(recall.getRecall1())\n",
        "\n",
        "        #print(\"TP ACERTOU\")\n",
        "    #caso prediction acerte, faz update nas listas e no recall\n",
        "    else:\n",
        "      correctness_dist.append(0)\n",
        "      #Entra se a classe eh 0 e da update no recall 0\n",
        "      if (classe == 0):\n",
        "        FN = FN + 1\n",
        "        recall.updateRec0(0)\n",
        "        recall0list.append(recall.getRecall0())\n",
        "        #print(\"FN ERROU\")\n",
        "      #Entra se a classe eh 1 e da update no recall 1\n",
        "      else:\n",
        "        FP = FP + 1\n",
        "        recall.updateRec1(0)\n",
        "        recall1list.append(recall.getRecall1())\n",
        "        #print(\"FN ERROU\")\n",
        "\n",
        "    #poolCleanInstances.append(X)\n",
        "  #se control for train\n",
        "  if(control == TRAIN):\n",
        "    #adiciona a instancia na lista de instancias a serem treinadas, essas instancias so serao treinadas quando indexStream chegar no valor de periodicidadeTreinamento\n",
        "    poolTrainInstances.append(X)\n",
        "    if(X[0,2] == 0):\n",
        "           # update the tree\n",
        "      poolCleanInstances.append(X)\n",
        "    if(X[0,2] == 1):\n",
        "      poolDefectInducingInstances.append(X)\n",
        "\n",
        "  #Caso indexStream chegue no valor de periodicidadeTreinamento, realizamos o treinamento percorrendo todas as instancias na lista poolTrainInstances e treinando o classificador com partial_fit\n",
        "  if(indexStream % periodicidadeTreinamento == 0):\n",
        "    #resetar  o classificador\n",
        "    #nao resetar o pool de instancias\n",
        "    #treinar o classificador com ten fold cross validation\n",
        "    #fazer isso pra 100, 500 e 1000 periodicidade\n",
        "    #\n",
        "    for inst in poolTrainInstances:\n",
        "\n",
        "      inst2 = np.array([inst[0,1:14]])\n",
        "      classe2 = np.array([int(inst[0,15])])\n",
        "\n",
        "      classifier.partial_fit(inst2, classe2)\n",
        "    indexStream=1\n",
        "    poolTrainInstances.clear()\n",
        "\n",
        "print(\"TP: \"+str(TP))\n",
        "print(\"FP: \"+str(FP))\n",
        "print(\"TN: \"+str(TN))\n",
        "print(\"FN: \"+str(FN))\n",
        "print(len(correctness_dist))\n",
        "print(sum(correctness_dist))\n",
        "print(classifier)\n",
        "\n",
        "#Organiza os recalls em uma lista e calcula gmean e por ultimo baixa como csv\n",
        "for i in range(abs(len(recall0list) - len(recall1list))):\n",
        "  if len(recall0list) > len(recall1list):\n",
        "    recall1list.append(recall1list[-1])\n",
        "  else:\n",
        "    recall0list.append(recall0list[-1])\n",
        "\n",
        "print(len(recall1list))\n",
        "print(len(recall0list))\n",
        "print(len(recall1list)+len(recall0list))\n",
        "\n",
        "gmeanList = []\n",
        "for i in range(len(recall0list)):\n",
        "  gmeanList.append(math.sqrt(recall0list[i] * recall1list[i]))\n",
        "\n",
        "print(len(gmeanList))\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "results = pd.DataFrame(\n",
        "    {'recall0': recall0list,\n",
        "     'recall1': recall1list,\n",
        "     'gmean': gmeanList\n",
        "    })\n",
        "\n",
        "results.to_csv('results.csv')\n",
        "files.download('results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}